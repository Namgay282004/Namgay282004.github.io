---
Title: DAM101 UnitTwo
categories: [DAM101, UnitTwo]
tags: [DAM101]
---
### Topic : UNIT 2(Data Preprocessing; Text and Image Processing)

Warm greetings to all my readers! First things first, it's important to recollect on what preprocessing techniques are used while training simple models. If I list out some of the techniques, such as identifying and handling missing values, handling null values, normalization, handling outliers, and splitting the dataset into training and testing sets. Having said that, let's dive into today's discussion that is about text preprocessing and image preprocessing.

#### Intoduction to NLP

Natural Language Processing is a branch of Artificial Intelligence that analyzes, processes, and efficiently retrieves information text data.

#### Text Prerocessing

Text preprocessing is a crucial step in preparing text data for machine learning models. It involves cleaning the text to remove noise, such as emojis and punctuation, and converting words into numbers. This conversion is necessary because machines work with numbers, not words, to understand and process text effectively.

#### Libraries used to deal with NLP problems

NLTK(Natural Language Toolkit) is mostly used library for some basic text cleaning.

#### Techniques for Text Preprocessing

Letâ€™s make our hands dirty by learning the techniques mostly used to clean text and make it noise-free.

1. **Lower Case**: If the text is in the same case, it is easy for a machine to interpret the words because the lower case and upper case are treated differently by the machine. For example, words like Teacher and teacher are treated differently by machine. So, we need to make the text in the same case and the most preferred case is a lower case.
```
data['text'] = data['text'].lower()
```

2. **Remove Punctuations**: There are total 32 main punctuations that need to be taken care of. we can directly use the string module with a regular expression to replace any punctuation in text with an empty string. 32 punctuations which string module provide us is listed below.
```
!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~
```

Code to remove punctuation is
```
data['text'] = data['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))
```

3. **Removal of Stopwords**: Stopwords are the most commonly occurring words in a text which do not provide any valuable information. stopwords like they, there, this, where, etc are some of the stopwords. NLTK library is a common library that is used to remove stopwords and include approximately 180 stopwords which it removes.

4. **Stemming and Lemmatization**: Stemming is a process to reduce the word to its root word for example run, running, runs derived from the same word as run. Basically what stemming does is remove the prefix or suffix from word like ing, s, es, etc. NLTK library is used to stem the words. The stemming technique is not used for production purposes because it is not so efficient technique and most of the time it stems the unwanted words. So, to solve the problem another technique came into the market as Lemmatization.

Like stemming, lemmatizing reduces words to their core meaning, but it will give you a complete English word that makes sense on its own instead of just a fragment of a word like 'discoveri'.

**Note**: A lemma is a word that represents a whole group of words, and that group of words is called a lexeme.

![alt text](../stemming_vs_lemmatization-1.png)

#### Image Prerocessing
hello